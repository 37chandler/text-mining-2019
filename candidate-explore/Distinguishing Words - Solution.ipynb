{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll try to figure out which words a candidates uses much more than other candidates. \n",
    "\n",
    "What is our criteria? To start with, let's say the word has to be in the top 100 (excluding stopwords) for a candidate and to represent a \"much\" higher percentage of their words. To make life easy, we'll just look for those words *not* in the top 100 for \"most\" of the other candidates. We'll also add a filter that the candidate must use the word 5 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re \n",
    "from collections import Counter, defaultdict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_candidate_text(text_list) :\n",
    "    # given a list of raw text, returns a list of words\n",
    "    words = []\n",
    "\n",
    "    for text in text_list :\n",
    "        text = [word.lower() for word in text.split()]\n",
    "        text = [word.strip() for word in text if word.isalpha()]\n",
    "        text = [word for word in text if word not in sw]\n",
    "        words.extend(text)\n",
    "        \n",
    "    return(words)\n",
    "\n",
    "def count_term(term,words,verbose=False) :\n",
    "    # Given a single-word term to look for and a list of words,\n",
    "    # returns the count of that term.\n",
    "    word_count = Counter(words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    if term in word_count :\n",
    "        if verbose :\n",
    "            print(\"Out of {} words, {} were '{}'.\".format(total_words,\n",
    "                                                        word_count[term],\n",
    "                                                        term))\n",
    "        return(word_count[term])\n",
    "    else :\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "db_path = \"C://users//jchan//dropbox//teaching//2019//textmining//text-mining-2019//web-scraping//candidate//\"\n",
    "db = sqlite3.connect(db_path + \"candidate_websites.db\") # feel free to change this to something you like. \n",
    "cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a list of candidates\n",
    "cur.execute(\"SELECT DISTINCT base_url, text FROM site_text\")\n",
    "candi_text = defaultdict(list) # let's talk about this\n",
    "\n",
    "for row in cur.fetchall() :\n",
    "    candidate, text = row\n",
    "    candi_text[candidate].append(text)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get clean words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candi_words = defaultdict(list)\n",
    "\n",
    "for candidate in candi_text :\n",
    "    candi_words[candidate] = clean_candidate_text(candi_text[candidate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go candidate by candidate and find the top 100 words and see if they're top 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_unique_words = defaultdict(lambda: defaultdict(int)) #going to have several levels.\n",
    "\n",
    "for candidate in candi_words :\n",
    "    this_count = Counter(candi_words[candidate]).most_common(100)\n",
    "    num_missing_from_others = defaultdict(int)\n",
    "    \n",
    "    top_100 = {w for w, cnt in this_count if cnt > 5}\n",
    "    \n",
    "    for candi_2 in candi_words : # iterate over the same dict\n",
    "        if candi_2 != candidate :\n",
    "            this_count_2 = Counter(candi_words[candi_2]).most_common(100)\n",
    "            top_100_2 = {w for w, cnt in this_count_2}\n",
    "            \n",
    "            for word in top_100 :\n",
    "                if word not in top_100_2 :\n",
    "                    num_missing_from_others[word] += 1\n",
    "                                \n",
    "    for word, cnt in num_missing_from_others.items() :\n",
    "        if cnt >= 9 :\n",
    "            candidate_unique_words[candidate][word] = cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candi in candidate_unique_words :\n",
    "    for word, cnt in candidate_unique_words[candi].items() :\n",
    "        print(\"{} uniquely uses the word '{}'.\".format(candi,word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
